{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd568abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "mingw_bin = \"C:/msys64/mingw64/bin\"\n",
    "os.add_dll_directory(mingw_bin)\n",
    "import ctypes\n",
    "lin = ctypes.cdll.LoadLibrary(\"./cmake-build-debug/liblinear_model.dll\")\n",
    "\n",
    "lin.create_linear_model.argtypes = [ctypes.c_int32]\n",
    "lin.create_linear_model.restype = ctypes.c_void_p\n",
    "\n",
    "lin.predict_linear_model.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_float)]\n",
    "lin.predict_linear_model.restype = ctypes.c_float\n",
    "\n",
    "lin.release_linear_model.argtypes = [ctypes.c_void_p]\n",
    "lin.release_linear_model.restype = None\n",
    "\n",
    "lin.train_linear_model.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_float), ctypes.POINTER(ctypes.c_float), ctypes.c_int32, ctypes.c_float, ctypes.c_int32]\n",
    "lin.train_linear_model.restype = None\n",
    "\n",
    "lin.create_ovo_classifier.argtypes = [ctypes.c_int32]\n",
    "lin.create_ovo_classifier.restype = ctypes.c_void_p\n",
    "\n",
    "lin.train_ovo_classifier.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_float), ctypes.POINTER(ctypes.c_int32), ctypes.c_int32, ctypes.c_int32, ctypes.c_float]\n",
    "lin.train_ovo_classifier.restype = None\n",
    "\n",
    "lin.predict_ovo_classifier.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_float)]\n",
    "lin.predict_ovo_classifier.restype = ctypes.c_int32\n",
    "\n",
    "lin.release_ovo_classifier.argtypes = [ctypes.c_void_p]\n",
    "lin.release_ovo_classifier.restype = None\n",
    "\n",
    "\n",
    "mlp = ctypes.cdll.LoadLibrary(\"./cmake-build-debug/libmlp.dll\") \n",
    "\n",
    "mlp.create_mlp_model.argtypes = [ctypes.POINTER(ctypes.c_int), ctypes.c_int]\n",
    "mlp.create_mlp_model.restype = ctypes.c_void_p\n",
    "\n",
    "mlp.train_mlp_model.argtypes = [\n",
    "    ctypes.c_void_p,\n",
    "    ctypes.POINTER(ctypes.c_float),\n",
    "    ctypes.POINTER(ctypes.c_float),\n",
    "    ctypes.c_int,\n",
    "    ctypes.c_float,\n",
    "    ctypes.c_int,\n",
    "    ctypes.c_bool,\n",
    "    ctypes.POINTER(ctypes.c_float),\n",
    "    ctypes.POINTER(ctypes.c_float),\n",
    "    ctypes.c_int\n",
    "]\n",
    "mlp.predict_mlp_model.restype = ctypes.POINTER(ctypes.c_float)\n",
    "\n",
    "mlp.predict_mlp_model.argtypes = [\n",
    "    ctypes.c_void_p,\n",
    "    ctypes.POINTER(ctypes.c_float),\n",
    "    ctypes.c_bool\n",
    "]\n",
    "\n",
    "mlp.release_mlp_model.argtypes = [ctypes.c_void_p]\n",
    "\n",
    "LOG_FUNC_TYPE = ctypes.CFUNCTYPE(None, ctypes.c_char_p)\n",
    "\n",
    "@LOG_FUNC_TYPE\n",
    "def logger_callback(msg):\n",
    "    print(msg.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fea4d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "classnames_array = ['buffalo', 'elephant', 'zebre']\n",
    "size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39acd93b",
   "metadata": {},
   "source": [
    "### Changement de r√©solution des images du dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d6b9071",
   "metadata": {},
   "outputs": [],
   "source": [
    "for classname in classnames_array:\n",
    "    folder_path = 'images/' + classname \n",
    "    for filename in os.listdir(folder_path):\n",
    "        img = Image.open(folder_path + '/' + filename).convert(\"RGB\")\n",
    "        img = img.resize(size=(size,size))\n",
    "        new_folder = './images' + str(size) + '/' + classname\n",
    "        if not os.path.exists(new_folder):\n",
    "            os.makedirs(new_folder)\n",
    "        img.save(new_folder + '/' + filename, format=\"JPEG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fec502",
   "metadata": {},
   "source": [
    "### Organisation du Dataset pour l'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eb284d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "folder_path = './images32/'\n",
    "for classname in os.listdir(folder_path):  \n",
    "    for filename in os.listdir(folder_path + classname):\n",
    "        img = Image.open(folder_path + classname + '/' + filename)\n",
    "        index = classname.index(classname)\n",
    "        one_hot = np.zeros(len(classnames_array))\n",
    "        one_hot[index] = 1.0\n",
    "        img_array = np.array(img) / 255.0\n",
    "        data.append([one_hot, img_array])\n",
    "data = np.array(data, dtype=object)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35929a87",
   "metadata": {},
   "source": [
    "### Test avec MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "831b2cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[C++ LOG] Epoch 500: Accuracy = 86.50%\n",
      "[C++ LOG] Epoch 1000: Accuracy = 93.36%\n",
      "[C++ LOG] Epoch 1500: Accuracy = 95.13%\n",
      "[C++ LOG] Epoch 2000: Accuracy = 95.80%\n",
      "[C++ LOG] Epoch 2500: Accuracy = 95.80%\n",
      "[C++ LOG] Epoch 3000: Accuracy = 95.80%\n",
      "[C++ LOG] Epoch 3500: Accuracy = 95.80%\n",
      "[C++ LOG] Epoch 4000: Accuracy = 95.80%\n",
      "[C++ LOG] Epoch 4500: Accuracy = 95.80%\n",
      "[C++ LOG] Epoch 5000: Accuracy = 96.02%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_sizes = [size*size*3, 256, 64, 32, 16, len(classnames_array)]\n",
    "layer_array = (ctypes.c_int * len(layer_sizes))(*layer_sizes)\n",
    "model = mlp.create_mlp_model(layer_array, len(layer_sizes) - 1)\n",
    "mlp.set_logger(logger_callback)\n",
    "\n",
    "np.random.shuffle(data)\n",
    "split_index = int(len(data) * 0.8)\n",
    "data_train = data[:split_index]\n",
    "data_test = data[split_index:]\n",
    "X_train = np.array([item[1] for item in data_train], dtype=np.float32)\n",
    "Y_train = np.array([item[0] for item in data_train], dtype=np.float32)\n",
    "X_test = np.array([item[1] for item in data_test], dtype=np.float32)\n",
    "Y_test = np.array([item[0] for item in data_test], dtype=np.float32)\n",
    "\n",
    "\n",
    "\n",
    "X_train_reshaped = X_train.reshape((X_train.shape[0], -1))  # (N, 3072)\n",
    "X_train_c = X_train_reshaped.ctypes.data_as(ctypes.POINTER(ctypes.c_float))\n",
    "Y_train_c = Y_train.ctypes.data_as(ctypes.POINTER(ctypes.c_float))\n",
    "X_test_reshaped = X_test.reshape((X_test.shape[0], -1))  # (N, 3072)\n",
    "X_test_c = X_test_reshaped.ctypes.data_as(ctypes.POINTER(ctypes.c_float))\n",
    "Y_test_c = Y_test.ctypes.data_as(ctypes.POINTER(ctypes.c_float))\n",
    "epochs = 5000\n",
    "learning_rate = 0.01\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "mlp.train_mlp_model(model, X_train_c, Y_train_c, epochs, learning_rate, batch_size, True, X_test_c, Y_test_c, len(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beac8d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "29/29 - 1s - 34ms/step - accuracy: 0.3193 - loss: 5.5564 - val_accuracy: 0.3348 - val_loss: 1.6179\n",
      "Epoch 2/200\n",
      "29/29 - 0s - 6ms/step - accuracy: 0.3613 - loss: 1.1640 - val_accuracy: 0.4846 - val_loss: 1.0505\n",
      "Epoch 3/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.4464 - loss: 1.0819 - val_accuracy: 0.3833 - val_loss: 1.1824\n",
      "Epoch 4/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.4188 - loss: 1.0675 - val_accuracy: 0.4361 - val_loss: 1.0875\n",
      "Epoch 5/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.4718 - loss: 1.0517 - val_accuracy: 0.5110 - val_loss: 0.9998\n",
      "Epoch 6/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.5083 - loss: 0.9950 - val_accuracy: 0.4097 - val_loss: 1.0961\n",
      "Epoch 7/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.4343 - loss: 1.0592 - val_accuracy: 0.4846 - val_loss: 0.9952\n",
      "Epoch 8/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.5481 - loss: 0.9802 - val_accuracy: 0.4581 - val_loss: 1.0064\n",
      "Epoch 9/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.5525 - loss: 0.9607 - val_accuracy: 0.5727 - val_loss: 0.9750\n",
      "Epoch 10/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.5271 - loss: 0.9693 - val_accuracy: 0.4934 - val_loss: 0.9747\n",
      "Epoch 11/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.6033 - loss: 0.9190 - val_accuracy: 0.5551 - val_loss: 0.9512\n",
      "Epoch 12/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.5492 - loss: 0.9486 - val_accuracy: 0.5463 - val_loss: 0.9530\n",
      "Epoch 13/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.5613 - loss: 0.9424 - val_accuracy: 0.5595 - val_loss: 0.9531\n",
      "Epoch 14/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.6011 - loss: 0.9107 - val_accuracy: 0.5595 - val_loss: 0.9684\n",
      "Epoch 15/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.6155 - loss: 0.8790 - val_accuracy: 0.5374 - val_loss: 0.9810\n",
      "Epoch 16/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.6232 - loss: 0.8402 - val_accuracy: 0.4802 - val_loss: 1.0369\n",
      "Epoch 17/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.6144 - loss: 0.8437 - val_accuracy: 0.5947 - val_loss: 0.8999\n",
      "Epoch 18/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.6276 - loss: 0.8370 - val_accuracy: 0.5595 - val_loss: 0.9480\n",
      "Epoch 19/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.6331 - loss: 0.8388 - val_accuracy: 0.5551 - val_loss: 0.9721\n",
      "Epoch 20/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.6155 - loss: 0.8735 - val_accuracy: 0.5595 - val_loss: 0.9176\n",
      "Epoch 21/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.6564 - loss: 0.7997 - val_accuracy: 0.5727 - val_loss: 0.9085\n",
      "Epoch 22/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.6663 - loss: 0.7713 - val_accuracy: 0.4229 - val_loss: 1.2184\n",
      "Epoch 23/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.6022 - loss: 0.8866 - val_accuracy: 0.5507 - val_loss: 0.9449\n",
      "Epoch 24/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.6575 - loss: 0.8001 - val_accuracy: 0.5595 - val_loss: 1.0172\n",
      "Epoch 25/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.6464 - loss: 0.8122 - val_accuracy: 0.5595 - val_loss: 0.9195\n",
      "Epoch 26/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.6707 - loss: 0.7797 - val_accuracy: 0.4581 - val_loss: 1.0525\n",
      "Epoch 27/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.6906 - loss: 0.7327 - val_accuracy: 0.5639 - val_loss: 1.0926\n",
      "Epoch 28/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.6751 - loss: 0.7834 - val_accuracy: 0.5595 - val_loss: 0.9529\n",
      "Epoch 29/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.6762 - loss: 0.7573 - val_accuracy: 0.5595 - val_loss: 0.9670\n",
      "Epoch 30/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7326 - loss: 0.6799 - val_accuracy: 0.5903 - val_loss: 0.9596\n",
      "Epoch 31/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7072 - loss: 0.7167 - val_accuracy: 0.5771 - val_loss: 0.9146\n",
      "Epoch 32/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.6354 - loss: 0.9012 - val_accuracy: 0.5286 - val_loss: 0.9859\n",
      "Epoch 33/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.6917 - loss: 0.7284 - val_accuracy: 0.5947 - val_loss: 0.9345\n",
      "Epoch 34/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7271 - loss: 0.6631 - val_accuracy: 0.5815 - val_loss: 1.0080\n",
      "Epoch 35/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7381 - loss: 0.6557 - val_accuracy: 0.5947 - val_loss: 0.9402\n",
      "Epoch 36/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7337 - loss: 0.6507 - val_accuracy: 0.5947 - val_loss: 0.9774\n",
      "Epoch 37/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7260 - loss: 0.6507 - val_accuracy: 0.4537 - val_loss: 1.6635\n",
      "Epoch 38/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.6541 - loss: 0.8457 - val_accuracy: 0.5507 - val_loss: 0.9975\n",
      "Epoch 39/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.6641 - loss: 0.7552 - val_accuracy: 0.5727 - val_loss: 0.9549\n",
      "Epoch 40/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7149 - loss: 0.6951 - val_accuracy: 0.5463 - val_loss: 1.0852\n",
      "Epoch 41/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7039 - loss: 0.7170 - val_accuracy: 0.5639 - val_loss: 1.0491\n",
      "Epoch 42/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7083 - loss: 0.6900 - val_accuracy: 0.5595 - val_loss: 0.9506\n",
      "Epoch 43/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7282 - loss: 0.6874 - val_accuracy: 0.4626 - val_loss: 1.1574\n",
      "Epoch 44/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7227 - loss: 0.6753 - val_accuracy: 0.5771 - val_loss: 0.9551\n",
      "Epoch 45/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.6818 - loss: 0.7247 - val_accuracy: 0.5551 - val_loss: 1.0157\n",
      "Epoch 46/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7227 - loss: 0.6850 - val_accuracy: 0.5859 - val_loss: 0.9737\n",
      "Epoch 47/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7304 - loss: 0.6535 - val_accuracy: 0.5683 - val_loss: 0.9438\n",
      "Epoch 48/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7337 - loss: 0.6559 - val_accuracy: 0.5507 - val_loss: 1.0400\n",
      "Epoch 49/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7503 - loss: 0.6361 - val_accuracy: 0.5551 - val_loss: 1.0204\n",
      "Epoch 50/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7481 - loss: 0.6057 - val_accuracy: 0.5991 - val_loss: 1.0153\n",
      "Epoch 51/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7646 - loss: 0.5651 - val_accuracy: 0.5595 - val_loss: 1.0174\n",
      "Epoch 52/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7602 - loss: 0.5958 - val_accuracy: 0.6035 - val_loss: 0.9988\n",
      "Epoch 53/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.6906 - loss: 0.7422 - val_accuracy: 0.5286 - val_loss: 0.9793\n",
      "Epoch 54/200\n",
      "29/29 - 0s - 6ms/step - accuracy: 0.7326 - loss: 0.6379 - val_accuracy: 0.6035 - val_loss: 1.1553\n",
      "Epoch 55/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7558 - loss: 0.5937 - val_accuracy: 0.4890 - val_loss: 1.3636\n",
      "Epoch 56/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7017 - loss: 0.7088 - val_accuracy: 0.5374 - val_loss: 1.0441\n",
      "Epoch 57/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7547 - loss: 0.6110 - val_accuracy: 0.4846 - val_loss: 1.2197\n",
      "Epoch 58/200\n",
      "29/29 - 0s - 6ms/step - accuracy: 0.7381 - loss: 0.6492 - val_accuracy: 0.5374 - val_loss: 1.1092\n",
      "Epoch 59/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7624 - loss: 0.6024 - val_accuracy: 0.5551 - val_loss: 1.3072\n",
      "Epoch 60/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7657 - loss: 0.6174 - val_accuracy: 0.5903 - val_loss: 1.0356\n",
      "Epoch 61/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7713 - loss: 0.5593 - val_accuracy: 0.4890 - val_loss: 1.3127\n",
      "Epoch 62/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7569 - loss: 0.5801 - val_accuracy: 0.5771 - val_loss: 1.0271\n",
      "Epoch 63/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7624 - loss: 0.5939 - val_accuracy: 0.5374 - val_loss: 1.1500\n",
      "Epoch 64/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8000 - loss: 0.5255 - val_accuracy: 0.5683 - val_loss: 1.1905\n",
      "Epoch 65/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8066 - loss: 0.5010 - val_accuracy: 0.5374 - val_loss: 1.2864\n",
      "Epoch 66/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8066 - loss: 0.5008 - val_accuracy: 0.5463 - val_loss: 1.1715\n",
      "Epoch 67/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8033 - loss: 0.5335 - val_accuracy: 0.5727 - val_loss: 1.1003\n",
      "Epoch 68/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7845 - loss: 0.5601 - val_accuracy: 0.5551 - val_loss: 1.1213\n",
      "Epoch 69/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7646 - loss: 0.6141 - val_accuracy: 0.5374 - val_loss: 1.0815\n",
      "Epoch 70/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7823 - loss: 0.5722 - val_accuracy: 0.5507 - val_loss: 1.0598\n",
      "Epoch 71/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8000 - loss: 0.5091 - val_accuracy: 0.5639 - val_loss: 1.1750\n",
      "Epoch 72/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8000 - loss: 0.5195 - val_accuracy: 0.4097 - val_loss: 1.7653\n",
      "Epoch 73/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.6851 - loss: 0.7396 - val_accuracy: 0.5727 - val_loss: 1.0690\n",
      "Epoch 74/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7735 - loss: 0.6018 - val_accuracy: 0.5947 - val_loss: 1.0656\n",
      "Epoch 75/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8155 - loss: 0.4909 - val_accuracy: 0.5374 - val_loss: 1.2705\n",
      "Epoch 76/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8044 - loss: 0.5257 - val_accuracy: 0.5947 - val_loss: 1.1262\n",
      "Epoch 77/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8000 - loss: 0.4800 - val_accuracy: 0.5286 - val_loss: 1.5478\n",
      "Epoch 78/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.6807 - loss: 0.7910 - val_accuracy: 0.5903 - val_loss: 1.1431\n",
      "Epoch 79/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7326 - loss: 0.6639 - val_accuracy: 0.5771 - val_loss: 1.0693\n",
      "Epoch 80/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7039 - loss: 0.6896 - val_accuracy: 0.5551 - val_loss: 1.0679\n",
      "Epoch 81/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8044 - loss: 0.5171 - val_accuracy: 0.5815 - val_loss: 1.1831\n",
      "Epoch 82/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7823 - loss: 0.5232 - val_accuracy: 0.4626 - val_loss: 1.3931\n",
      "Epoch 83/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8077 - loss: 0.4915 - val_accuracy: 0.5330 - val_loss: 1.3042\n",
      "Epoch 84/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7293 - loss: 0.6249 - val_accuracy: 0.5374 - val_loss: 1.1234\n",
      "Epoch 85/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7923 - loss: 0.5397 - val_accuracy: 0.5330 - val_loss: 1.1505\n",
      "Epoch 86/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8265 - loss: 0.4517 - val_accuracy: 0.5727 - val_loss: 1.2069\n",
      "Epoch 87/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8475 - loss: 0.4295 - val_accuracy: 0.5374 - val_loss: 1.3304\n",
      "Epoch 88/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8155 - loss: 0.4971 - val_accuracy: 0.5683 - val_loss: 1.2452\n",
      "Epoch 89/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8508 - loss: 0.4162 - val_accuracy: 0.5595 - val_loss: 1.3245\n",
      "Epoch 90/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8530 - loss: 0.4136 - val_accuracy: 0.5947 - val_loss: 1.2796\n",
      "Epoch 91/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8354 - loss: 0.4272 - val_accuracy: 0.4758 - val_loss: 1.5077\n",
      "Epoch 92/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7613 - loss: 0.6251 - val_accuracy: 0.5551 - val_loss: 1.1837\n",
      "Epoch 93/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7956 - loss: 0.5287 - val_accuracy: 0.5110 - val_loss: 1.2787\n",
      "Epoch 94/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8022 - loss: 0.4904 - val_accuracy: 0.5154 - val_loss: 1.3387\n",
      "Epoch 95/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8497 - loss: 0.4240 - val_accuracy: 0.5242 - val_loss: 1.3050\n",
      "Epoch 96/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7989 - loss: 0.4936 - val_accuracy: 0.5683 - val_loss: 1.3570\n",
      "Epoch 97/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8685 - loss: 0.3783 - val_accuracy: 0.5991 - val_loss: 1.2345\n",
      "Epoch 98/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8707 - loss: 0.3639 - val_accuracy: 0.5903 - val_loss: 1.3260\n",
      "Epoch 99/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8453 - loss: 0.4211 - val_accuracy: 0.5639 - val_loss: 1.4045\n",
      "Epoch 100/200\n",
      "29/29 - 0s - 8ms/step - accuracy: 0.8376 - loss: 0.4562 - val_accuracy: 0.4846 - val_loss: 1.4049\n",
      "Epoch 101/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8530 - loss: 0.4087 - val_accuracy: 0.5595 - val_loss: 1.5278\n",
      "Epoch 102/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8276 - loss: 0.4615 - val_accuracy: 0.5374 - val_loss: 1.3710\n",
      "Epoch 103/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8674 - loss: 0.3908 - val_accuracy: 0.5374 - val_loss: 1.4830\n",
      "Epoch 104/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8862 - loss: 0.3454 - val_accuracy: 0.5419 - val_loss: 1.4700\n",
      "Epoch 105/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7591 - loss: 0.6297 - val_accuracy: 0.5595 - val_loss: 1.3000\n",
      "Epoch 106/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8751 - loss: 0.3752 - val_accuracy: 0.5066 - val_loss: 1.6023\n",
      "Epoch 107/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7967 - loss: 0.5389 - val_accuracy: 0.4802 - val_loss: 1.3806\n",
      "Epoch 108/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8232 - loss: 0.4603 - val_accuracy: 0.5727 - val_loss: 1.3021\n",
      "Epoch 109/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8486 - loss: 0.3882 - val_accuracy: 0.5815 - val_loss: 1.3274\n",
      "Epoch 110/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8972 - loss: 0.3180 - val_accuracy: 0.5374 - val_loss: 1.9409\n",
      "Epoch 111/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8022 - loss: 0.5158 - val_accuracy: 0.5463 - val_loss: 1.4685\n",
      "Epoch 112/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8796 - loss: 0.3292 - val_accuracy: 0.5727 - val_loss: 1.4974\n",
      "Epoch 113/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.9127 - loss: 0.2932 - val_accuracy: 0.5683 - val_loss: 1.4800\n",
      "Epoch 114/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8840 - loss: 0.3248 - val_accuracy: 0.5198 - val_loss: 1.6630\n",
      "Epoch 115/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8232 - loss: 0.4941 - val_accuracy: 0.5463 - val_loss: 1.7650\n",
      "Epoch 116/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8873 - loss: 0.3233 - val_accuracy: 0.5771 - val_loss: 1.4754\n",
      "Epoch 117/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8343 - loss: 0.4375 - val_accuracy: 0.5771 - val_loss: 1.4202\n",
      "Epoch 118/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.9094 - loss: 0.2790 - val_accuracy: 0.5463 - val_loss: 1.8893\n",
      "Epoch 119/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8983 - loss: 0.2963 - val_accuracy: 0.5330 - val_loss: 1.5184\n",
      "Epoch 120/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8762 - loss: 0.3390 - val_accuracy: 0.5727 - val_loss: 1.6074\n",
      "Epoch 121/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7193 - loss: 0.6931 - val_accuracy: 0.5771 - val_loss: 1.3259\n",
      "Epoch 122/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8221 - loss: 0.4678 - val_accuracy: 0.5815 - val_loss: 1.1743\n",
      "Epoch 123/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8608 - loss: 0.4100 - val_accuracy: 0.5815 - val_loss: 1.2589\n",
      "Epoch 124/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8420 - loss: 0.4117 - val_accuracy: 0.5639 - val_loss: 1.3088\n",
      "Epoch 125/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.9083 - loss: 0.2851 - val_accuracy: 0.5551 - val_loss: 1.5625\n",
      "Epoch 126/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8950 - loss: 0.3150 - val_accuracy: 0.5242 - val_loss: 2.0752\n",
      "Epoch 127/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7779 - loss: 0.6107 - val_accuracy: 0.5683 - val_loss: 1.2999\n",
      "Epoch 128/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8994 - loss: 0.3150 - val_accuracy: 0.5463 - val_loss: 1.3298\n",
      "Epoch 129/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8862 - loss: 0.3189 - val_accuracy: 0.5154 - val_loss: 1.6462\n",
      "Epoch 130/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8166 - loss: 0.4768 - val_accuracy: 0.4097 - val_loss: 1.7317\n",
      "Epoch 131/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7580 - loss: 0.6448 - val_accuracy: 0.5374 - val_loss: 1.3966\n",
      "Epoch 132/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8243 - loss: 0.4847 - val_accuracy: 0.5683 - val_loss: 1.4806\n",
      "Epoch 133/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.9017 - loss: 0.2961 - val_accuracy: 0.5683 - val_loss: 1.4140\n",
      "Epoch 134/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8961 - loss: 0.3099 - val_accuracy: 0.5463 - val_loss: 1.4182\n",
      "Epoch 135/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8619 - loss: 0.3935 - val_accuracy: 0.5639 - val_loss: 1.5303\n",
      "Epoch 136/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8630 - loss: 0.4019 - val_accuracy: 0.5330 - val_loss: 1.5277\n",
      "Epoch 137/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7713 - loss: 0.5499 - val_accuracy: 0.5374 - val_loss: 1.3392\n",
      "Epoch 138/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8762 - loss: 0.3744 - val_accuracy: 0.5771 - val_loss: 1.4461\n",
      "Epoch 139/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8718 - loss: 0.3729 - val_accuracy: 0.5595 - val_loss: 1.5796\n",
      "Epoch 140/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8254 - loss: 0.4376 - val_accuracy: 0.5859 - val_loss: 1.5186\n",
      "Epoch 141/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8586 - loss: 0.3685 - val_accuracy: 0.5374 - val_loss: 1.3324\n",
      "Epoch 142/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8740 - loss: 0.3649 - val_accuracy: 0.5198 - val_loss: 1.8697\n",
      "Epoch 143/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8906 - loss: 0.3268 - val_accuracy: 0.5683 - val_loss: 1.8598\n",
      "Epoch 144/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8751 - loss: 0.3486 - val_accuracy: 0.5242 - val_loss: 1.3656\n",
      "Epoch 145/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8641 - loss: 0.3758 - val_accuracy: 0.5595 - val_loss: 1.5420\n",
      "Epoch 146/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.9227 - loss: 0.2556 - val_accuracy: 0.5330 - val_loss: 1.6804\n",
      "Epoch 147/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8652 - loss: 0.3663 - val_accuracy: 0.5066 - val_loss: 1.6367\n",
      "Epoch 148/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.9028 - loss: 0.2800 - val_accuracy: 0.5771 - val_loss: 1.7331\n",
      "Epoch 149/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.9105 - loss: 0.2723 - val_accuracy: 0.5507 - val_loss: 2.5541\n",
      "Epoch 150/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8751 - loss: 0.3684 - val_accuracy: 0.5463 - val_loss: 1.7472\n",
      "Epoch 151/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.9127 - loss: 0.2630 - val_accuracy: 0.5595 - val_loss: 1.9012\n",
      "Epoch 152/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.9083 - loss: 0.2808 - val_accuracy: 0.5066 - val_loss: 2.1652\n",
      "Epoch 153/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.9227 - loss: 0.2373 - val_accuracy: 0.5595 - val_loss: 2.1177\n",
      "Epoch 154/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.9061 - loss: 0.2643 - val_accuracy: 0.5551 - val_loss: 2.1623\n",
      "Epoch 155/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.9028 - loss: 0.2614 - val_accuracy: 0.4537 - val_loss: 1.9173\n",
      "Epoch 156/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7039 - loss: 0.7957 - val_accuracy: 0.4537 - val_loss: 1.3008\n",
      "Epoch 157/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7613 - loss: 0.5813 - val_accuracy: 0.5551 - val_loss: 1.2073\n",
      "Epoch 158/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7856 - loss: 0.5549 - val_accuracy: 0.5198 - val_loss: 1.3525\n",
      "Epoch 159/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.6906 - loss: 0.8168 - val_accuracy: 0.4758 - val_loss: 1.1007\n",
      "Epoch 160/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.6939 - loss: 0.7531 - val_accuracy: 0.5419 - val_loss: 1.0478\n",
      "Epoch 161/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7923 - loss: 0.5237 - val_accuracy: 0.5374 - val_loss: 1.3134\n",
      "Epoch 162/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8000 - loss: 0.5058 - val_accuracy: 0.5419 - val_loss: 1.2066\n",
      "Epoch 163/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.6552 - loss: 0.8475 - val_accuracy: 0.3921 - val_loss: 1.1809\n",
      "Epoch 164/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.6884 - loss: 0.7546 - val_accuracy: 0.5463 - val_loss: 1.0801\n",
      "Epoch 165/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7403 - loss: 0.6081 - val_accuracy: 0.5330 - val_loss: 1.0348\n",
      "Epoch 166/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8088 - loss: 0.4962 - val_accuracy: 0.5771 - val_loss: 1.4261\n",
      "Epoch 167/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7845 - loss: 0.5551 - val_accuracy: 0.5683 - val_loss: 1.1914\n",
      "Epoch 168/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8365 - loss: 0.4199 - val_accuracy: 0.5463 - val_loss: 1.5124\n",
      "Epoch 169/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8387 - loss: 0.4277 - val_accuracy: 0.5374 - val_loss: 1.3849\n",
      "Epoch 170/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7768 - loss: 0.5441 - val_accuracy: 0.5595 - val_loss: 1.2436\n",
      "Epoch 171/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8331 - loss: 0.4538 - val_accuracy: 0.5551 - val_loss: 1.6445\n",
      "Epoch 172/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8287 - loss: 0.4506 - val_accuracy: 0.5595 - val_loss: 1.4549\n",
      "Epoch 173/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8464 - loss: 0.3923 - val_accuracy: 0.5507 - val_loss: 1.5481\n",
      "Epoch 174/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8718 - loss: 0.3729 - val_accuracy: 0.4670 - val_loss: 1.8713\n",
      "Epoch 175/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8707 - loss: 0.3621 - val_accuracy: 0.5507 - val_loss: 1.4419\n",
      "Epoch 176/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8884 - loss: 0.3289 - val_accuracy: 0.5639 - val_loss: 1.8720\n",
      "Epoch 177/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8398 - loss: 0.4200 - val_accuracy: 0.5198 - val_loss: 1.5121\n",
      "Epoch 178/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8541 - loss: 0.4083 - val_accuracy: 0.5595 - val_loss: 1.5527\n",
      "Epoch 179/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7149 - loss: 0.6914 - val_accuracy: 0.5374 - val_loss: 1.1011\n",
      "Epoch 180/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8674 - loss: 0.4097 - val_accuracy: 0.5727 - val_loss: 1.2899\n",
      "Epoch 181/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.7834 - loss: 0.5616 - val_accuracy: 0.5771 - val_loss: 1.1636\n",
      "Epoch 182/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8508 - loss: 0.3930 - val_accuracy: 0.5639 - val_loss: 1.3694\n",
      "Epoch 183/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8464 - loss: 0.4060 - val_accuracy: 0.5551 - val_loss: 1.3679\n",
      "Epoch 184/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8740 - loss: 0.3725 - val_accuracy: 0.5507 - val_loss: 1.6478\n",
      "Epoch 185/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8685 - loss: 0.3575 - val_accuracy: 0.5683 - val_loss: 1.2805\n",
      "Epoch 186/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8431 - loss: 0.4461 - val_accuracy: 0.5463 - val_loss: 1.2999\n",
      "Epoch 187/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8950 - loss: 0.3125 - val_accuracy: 0.5815 - val_loss: 1.7053\n",
      "Epoch 188/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8751 - loss: 0.3539 - val_accuracy: 0.5419 - val_loss: 1.4431\n",
      "Epoch 189/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8785 - loss: 0.3273 - val_accuracy: 0.5595 - val_loss: 1.5867\n",
      "Epoch 190/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8917 - loss: 0.3348 - val_accuracy: 0.5727 - val_loss: 1.5791\n",
      "Epoch 191/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.9249 - loss: 0.2472 - val_accuracy: 0.5859 - val_loss: 1.9613\n",
      "Epoch 192/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8773 - loss: 0.3238 - val_accuracy: 0.4890 - val_loss: 2.1824\n",
      "Epoch 193/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.5878 - loss: 1.0240 - val_accuracy: 0.4493 - val_loss: 1.1265\n",
      "Epoch 194/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.6088 - loss: 0.8604 - val_accuracy: 0.5551 - val_loss: 1.2481\n",
      "Epoch 195/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8486 - loss: 0.4514 - val_accuracy: 0.5595 - val_loss: 1.2729\n",
      "Epoch 196/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8895 - loss: 0.3454 - val_accuracy: 0.5683 - val_loss: 1.6301\n",
      "Epoch 197/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8530 - loss: 0.4327 - val_accuracy: 0.5595 - val_loss: 1.6275\n",
      "Epoch 198/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8033 - loss: 0.5115 - val_accuracy: 0.5463 - val_loss: 1.1866\n",
      "Epoch 199/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8519 - loss: 0.4038 - val_accuracy: 0.5551 - val_loss: 1.2627\n",
      "Epoch 200/200\n",
      "29/29 - 0s - 7ms/step - accuracy: 0.8851 - loss: 0.3299 - val_accuracy: 0.4846 - val_loss: 1.3743\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and multiclass targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 52\u001b[0m\n\u001b[0;32m     50\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test_reshaped)\n\u001b[0;32m     51\u001b[0m pred_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lgrdp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\lgrdp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:220\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 220\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\lgrdp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and multiclass targets"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train_reshaped = X_train.reshape((X_train.shape[0], -1))\n",
    "X_test_reshaped = X_test.reshape((X_test.shape[0], -1))\n",
    "Y_train_cat = to_categorical(Y_train, num_classes=len(classnames_array))\n",
    "Y_test_cat = to_categorical(Y_test, num_classes=len(classnames_array))\n",
    "\n",
    "def ensure_categorical(Y, num_classes):\n",
    "    Y = np.array(Y)\n",
    "    if len(Y.shape) == 1:\n",
    "        return to_categorical(Y, num_classes)\n",
    "    elif Y.shape[1] == num_classes:\n",
    "        return Y \n",
    "    else:\n",
    "        raise ValueError(f\"Format inattendu pour Y (shape: {Y.shape})\")\n",
    "\n",
    "Y_train_cat = ensure_categorical(Y_train, len(classnames_array))\n",
    "Y_test_cat = ensure_categorical(Y_test, len(classnames_array))\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train_reshaped.shape[1],)),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(len(classnames_array), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.01),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_reshaped, Y_train_cat,\n",
    "          epochs=200,\n",
    "          batch_size=32,\n",
    "          validation_data=(X_test_reshaped, Y_test_cat),\n",
    "          verbose=2)\n",
    "\n",
    "predictions = model.predict(X_test_reshaped)\n",
    "pred_labels = np.argmax(predictions, axis=1)\n",
    "acc = accuracy_score(Y_test, pred_labels)\n",
    "print(f\"\\nTest Accuracy: {acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdee9f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.release_mlp_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7f6c8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class : buffalo\n",
      "[0.999660313129425, -0.0020802810322493315, -0.43730825185775757]\n"
     ]
    }
   ],
   "source": [
    "img = Image.open('C:/Users/lgrdp/Downloads/images (1).jpeg').convert(\"RGB\")\n",
    "img = img.resize(size=(32,32))\n",
    "img_data = np.array(img) / 255.0\n",
    "\n",
    "output_array = mlp.predict_mlp_model(model, img_data.ctypes.data_as(ctypes.POINTER(ctypes.c_float)), True)\n",
    "output_array = ctypes.cast(output_array, ctypes.POINTER(ctypes.c_float * layer_sizes[-1])).contents\n",
    "output = list(output_array)\n",
    "class_index = 0\n",
    "for i in range(len(output)):\n",
    "    if output[i] == max(output):\n",
    "        class_index = i\n",
    "print('predicted class : ' + classnames_array[class_index])\n",
    "print(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
