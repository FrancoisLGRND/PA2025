{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd568abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import time\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "import pandas as pd\n",
    "\n",
    "mingw_bin = \"C:/msys64/mingw64/bin\"\n",
    "os.add_dll_directory(mingw_bin)\n",
    "import ctypes\n",
    "lin = ctypes.cdll.LoadLibrary(\"./cmake-build-debug/liblinear_model.dll\")\n",
    "\n",
    "lin.create_linear_model.argtypes = [ctypes.c_int32]\n",
    "lin.create_linear_model.restype = ctypes.c_void_p\n",
    "\n",
    "lin.predict_linear_model.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_float)]\n",
    "lin.predict_linear_model.restype = ctypes.c_float\n",
    "\n",
    "lin.release_linear_model.argtypes = [ctypes.c_void_p]\n",
    "lin.release_linear_model.restype = None\n",
    "\n",
    "lin.train_linear_model.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_float), ctypes.POINTER(ctypes.c_float), ctypes.c_int32, ctypes.c_float, ctypes.c_int32]\n",
    "lin.train_linear_model.restype = None\n",
    "\n",
    "lin.create_ovo_classifier.argtypes = [ctypes.c_int32]\n",
    "lin.create_ovo_classifier.restype = ctypes.c_void_p\n",
    "\n",
    "lin.train_ovo_classifier.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_float), ctypes.POINTER(ctypes.c_int32), ctypes.c_int32, ctypes.c_int32, ctypes.c_float]\n",
    "lin.train_ovo_classifier.restype = None\n",
    "\n",
    "lin.predict_ovo_classifier.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_float)]\n",
    "lin.predict_ovo_classifier.restype = ctypes.c_int32\n",
    "\n",
    "lin.release_ovo_classifier.argtypes = [ctypes.c_void_p]\n",
    "lin.release_ovo_classifier.restype = None\n",
    "\n",
    "\n",
    "mlp = ctypes.cdll.LoadLibrary(\"./cmake-build-debug/libmlp.dll\") \n",
    "\n",
    "mlp.create_mlp_model.argtypes = [ctypes.POINTER(ctypes.c_int), ctypes.c_int]\n",
    "mlp.create_mlp_model.restype = ctypes.c_void_p\n",
    "\n",
    "mlp.train_mlp_model.argtypes = [\n",
    "    ctypes.c_void_p,\n",
    "    ctypes.POINTER(ctypes.c_float),\n",
    "    ctypes.POINTER(ctypes.c_float),\n",
    "    ctypes.c_int,\n",
    "    ctypes.c_int,\n",
    "    ctypes.c_float,\n",
    "    ctypes.c_int,\n",
    "    ctypes.c_bool,\n",
    "    ctypes.c_char_p, \n",
    "    ctypes.POINTER(ctypes.c_float),\n",
    "    ctypes.POINTER(ctypes.c_float),\n",
    "    ctypes.c_int\n",
    "]\n",
    "mlp.predict_mlp_model.restype = ctypes.POINTER(ctypes.c_float)\n",
    "\n",
    "mlp.predict_mlp_model.argtypes = [\n",
    "    ctypes.c_void_p,\n",
    "    ctypes.POINTER(ctypes.c_float),\n",
    "    ctypes.c_bool\n",
    "]\n",
    "\n",
    "mlp.release_mlp_model.argtypes = [ctypes.c_void_p]\n",
    "\n",
    "mlp.get_confusion_matrix.argtypes = [ctypes.c_void_p, ctypes.POINTER(ctypes.c_int32)]\n",
    "mlp.get_confusion_matrix.restype = None\n",
    "\n",
    "mlp.evaluate_confusion_matrix.argtypes = [\n",
    "    ctypes.c_void_p,\n",
    "    ctypes.POINTER(ctypes.c_float),\n",
    "    ctypes.POINTER(ctypes.c_float),\n",
    "    ctypes.c_int,\n",
    "    ctypes.c_bool \n",
    "]\n",
    "mlp.evaluate_confusion_matrix.restype = None\n",
    "\n",
    "LOG_FUNC_TYPE = ctypes.CFUNCTYPE(None, ctypes.c_char_p)\n",
    "\n",
    "@LOG_FUNC_TYPE\n",
    "def logger_callback(msg):\n",
    "    print(msg.decode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949727ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fea4d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "classnames_array = ['buffalo', 'elephant', 'zebre']\n",
    "size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39acd93b",
   "metadata": {},
   "source": [
    "### Changement de résolution des images du dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d6b9071",
   "metadata": {},
   "outputs": [],
   "source": [
    "for classname in classnames_array:\n",
    "    folder_path = 'images/' + classname \n",
    "    for filename in os.listdir(folder_path):\n",
    "        img = Image.open(folder_path + '/' + filename).convert(\"RGB\")\n",
    "        img = img.resize(size=(size,size))\n",
    "        new_folder = './images' + str(size) + '/' + classname\n",
    "        if not os.path.exists(new_folder):\n",
    "            os.makedirs(new_folder)\n",
    "        img.save(new_folder + '/' + filename, format=\"JPEG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fec502",
   "metadata": {},
   "source": [
    "### Organisation du Dataset pour l'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8eb284d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "folder_path = './images32/'\n",
    "for classname in os.listdir(folder_path):  \n",
    "    for filename in os.listdir(folder_path + classname):\n",
    "        img = Image.open(folder_path + classname + '/' + filename)\n",
    "        \n",
    "        # Trouver l'index correct dans classnames_array\n",
    "        index = classnames_array.index(classname)  \n",
    "        \n",
    "        one_hot = np.zeros(len(classnames_array), dtype=np.float32)\n",
    "        one_hot[index] = 1.0\n",
    "        \n",
    "        img_array = (np.array(img) / 255.0) - 1.0\n",
    "        data.append([one_hot, img_array])\n",
    "\n",
    "data = np.array(data, dtype=object)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35929a87",
   "metadata": {},
   "source": [
    "### Test avec MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831b2cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: acc = 39.66%, loss = 2.2564\n",
      "Epoch 20: acc = 40.08%, loss = 2.0630\n",
      "Epoch 30: acc = 42.62%, loss = 1.9729\n",
      "Epoch 40: acc = 44.73%, loss = 1.8311\n",
      "Epoch 50: acc = 45.99%, loss = 1.7202\n",
      "Epoch 60: acc = 45.99%, loss = 1.8388\n",
      "Epoch 70: acc = 42.19%, loss = 1.7618\n",
      "Epoch 80: acc = 43.46%, loss = 1.7502\n",
      "Epoch 90: acc = 40.93%, loss = 1.7231\n",
      "Epoch 100: acc = 45.57%, loss = 1.6764\n",
      "Epoch 110: acc = 46.84%, loss = 1.6824\n",
      "Epoch 120: acc = 45.15%, loss = 1.7396\n",
      "Epoch 130: acc = 43.46%, loss = 1.6946\n",
      "Epoch 140: acc = 47.68%, loss = 1.6232\n",
      "Epoch 150: acc = 48.52%, loss = 1.5628\n",
      "Epoch 160: acc = 45.15%, loss = 1.5279\n",
      "Epoch 170: acc = 46.84%, loss = 1.5363\n",
      "Epoch 180: acc = 50.21%, loss = 1.4498\n",
      "Epoch 190: acc = 47.68%, loss = 1.4507\n",
      "Epoch 200: acc = 47.26%, loss = 1.4800\n",
      "Epoch 210: acc = 48.10%, loss = 1.4876\n",
      "Epoch 220: acc = 45.99%, loss = 1.4918\n",
      "Epoch 230: acc = 47.26%, loss = 1.5182\n",
      "Epoch 240: acc = 43.04%, loss = 1.4758\n",
      "Epoch 250: acc = 43.88%, loss = 1.4559\n",
      "Epoch 260: acc = 45.57%, loss = 1.4136\n",
      "Epoch 270: acc = 44.73%, loss = 1.4563\n",
      "Epoch 280: acc = 48.52%, loss = 1.4339\n",
      "Epoch 290: acc = 45.99%, loss = 1.4051\n",
      "Epoch 300: acc = 44.73%, loss = 1.3765\n",
      "Epoch 310: acc = 45.99%, loss = 1.3951\n",
      "Epoch 320: acc = 48.10%, loss = 1.3535\n",
      "Epoch 330: acc = 47.26%, loss = 1.3704\n",
      "Epoch 340: acc = 48.10%, loss = 1.3787\n",
      "Epoch 350: acc = 46.84%, loss = 1.3960\n",
      "Epoch 360: acc = 46.41%, loss = 1.3854\n",
      "Epoch 370: acc = 48.10%, loss = 1.3359\n",
      "Epoch 380: acc = 48.52%, loss = 1.3388\n",
      "Epoch 390: acc = 48.10%, loss = 1.3707\n",
      "Epoch 400: acc = 48.10%, loss = 1.3385\n",
      "Epoch 410: acc = 49.79%, loss = 1.3357\n",
      "Epoch 420: acc = 49.37%, loss = 1.3232\n",
      "Epoch 430: acc = 50.63%, loss = 1.3527\n",
      "Epoch 440: acc = 49.79%, loss = 1.3487\n",
      "Epoch 450: acc = 48.95%, loss = 1.3295\n",
      "Epoch 460: acc = 48.95%, loss = 1.3315\n",
      "Epoch 470: acc = 47.26%, loss = 1.3306\n",
      "Epoch 480: acc = 48.52%, loss = 1.3155\n",
      "Epoch 490: acc = 47.26%, loss = 1.3300\n",
      "Epoch 500: acc = 49.37%, loss = 1.3190\n",
      "Epoch 510: acc = 49.37%, loss = 1.3498\n",
      "Epoch 520: acc = 48.52%, loss = 1.3288\n",
      "Epoch 530: acc = 48.10%, loss = 1.3328\n",
      "Epoch 540: acc = 50.63%, loss = 1.3205\n",
      "Epoch 550: acc = 49.37%, loss = 1.3390\n",
      "Epoch 560: acc = 48.95%, loss = 1.3243\n",
      "Epoch 570: acc = 50.63%, loss = 1.3256\n",
      "Epoch 580: acc = 48.10%, loss = 1.3523\n",
      "Epoch 590: acc = 47.26%, loss = 1.3390\n",
      "Epoch 600: acc = 48.10%, loss = 1.3261\n",
      "Epoch 610: acc = 47.68%, loss = 1.3328\n",
      "Epoch 620: acc = 49.37%, loss = 1.3431\n",
      "Epoch 630: acc = 49.37%, loss = 1.3238\n",
      "Epoch 640: acc = 48.95%, loss = 1.2995\n",
      "Epoch 650: acc = 49.37%, loss = 1.3072\n",
      "Epoch 660: acc = 51.05%, loss = 1.3265\n",
      "Epoch 670: acc = 50.21%, loss = 1.3501\n",
      "Epoch 680: acc = 49.37%, loss = 1.3435\n",
      "Epoch 690: acc = 49.79%, loss = 1.3028\n",
      "Epoch 700: acc = 50.63%, loss = 1.3310\n",
      "Epoch 710: acc = 51.05%, loss = 1.3468\n",
      "Epoch 720: acc = 50.63%, loss = 1.3414\n",
      "Epoch 730: acc = 47.68%, loss = 1.3640\n",
      "Epoch 740: acc = 47.26%, loss = 1.3779\n",
      "Epoch 750: acc = 48.95%, loss = 1.3384\n",
      "Epoch 760: acc = 50.21%, loss = 1.3345\n",
      "Epoch 770: acc = 50.21%, loss = 1.3271\n",
      "Epoch 780: acc = 49.79%, loss = 1.3440\n",
      "Epoch 790: acc = 49.79%, loss = 1.3144\n",
      "Epoch 800: acc = 49.37%, loss = 1.3177\n",
      "Epoch 810: acc = 48.95%, loss = 1.3399\n",
      "Epoch 820: acc = 51.48%, loss = 1.3300\n",
      "Epoch 830: acc = 51.48%, loss = 1.3327\n",
      "Epoch 840: acc = 50.63%, loss = 1.3337\n",
      "Epoch 850: acc = 51.90%, loss = 1.3408\n",
      "Epoch 860: acc = 51.48%, loss = 1.3289\n",
      "Epoch 870: acc = 51.05%, loss = 1.3504\n",
      "Epoch 880: acc = 49.37%, loss = 1.3357\n",
      "Epoch 890: acc = 50.21%, loss = 1.3496\n",
      "Epoch 900: acc = 50.63%, loss = 1.3141\n",
      "Epoch 910: acc = 52.32%, loss = 1.3196\n",
      "Epoch 920: acc = 51.90%, loss = 1.3252\n",
      "Epoch 930: acc = 50.63%, loss = 1.3218\n",
      "Epoch 940: acc = 51.05%, loss = 1.3243\n",
      "Epoch 950: acc = 51.48%, loss = 1.3179\n",
      "Epoch 960: acc = 51.48%, loss = 1.3374\n",
      "Epoch 970: acc = 51.05%, loss = 1.3232\n",
      "Epoch 980: acc = 51.48%, loss = 1.3350\n",
      "Epoch 990: acc = 51.90%, loss = 1.3398\n",
      "Epoch 1000: acc = 52.32%, loss = 1.3134\n",
      "[[41 20 15]\n",
      " [20 39 22]\n",
      " [12 24 44]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 52\u001b[0m\n\u001b[0;32m     50\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m     51\u001b[0m sns\u001b[38;5;241m.\u001b[39mset(font_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.2\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheatmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfusion_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43md\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBlues\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mxticklabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassnames_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myticklabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassnames_array\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mlinewidths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgray\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatrice de confusion\u001b[39m\u001b[38;5;124m\"\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n\u001b[0;32m     57\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClasse prédite\u001b[39m\u001b[38;5;124m\"\u001b[39m, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m14\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lgrdp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\matrix.py:446\u001b[0m, in \u001b[0;36mheatmap\u001b[1;34m(data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, linewidths, linecolor, cbar, cbar_kws, cbar_ax, square, xticklabels, yticklabels, mask, ax, **kwargs)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Plot rectangular data as a color-encoded matrix.\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \n\u001b[0;32m    367\u001b[0m \u001b[38;5;124;03mThis is an Axes-level function and will draw the heatmap into the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    443\u001b[0m \n\u001b[0;32m    444\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# Initialize the plotter object\u001b[39;00m\n\u001b[1;32m--> 446\u001b[0m plotter \u001b[38;5;241m=\u001b[39m \u001b[43m_HeatMapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrobust\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    447\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mannot_kws\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbar_kws\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxticklabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    448\u001b[0m \u001b[43m                      \u001b[49m\u001b[43myticklabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# Add the pcolormesh kwargs here\u001b[39;00m\n\u001b[0;32m    451\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinewidths\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m linewidths\n",
      "File \u001b[1;32mc:\\Users\\lgrdp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\seaborn\\matrix.py:146\u001b[0m, in \u001b[0;36m_HeatMapper.__init__\u001b[1;34m(self, data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, cbar, cbar_kws, xticklabels, yticklabels, mask)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxticks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxticklabels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_skip_ticks(xticklabels,\n\u001b[0;32m    144\u001b[0m                                                      xtickevery)\n\u001b[1;32m--> 146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43myticklabels\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myticks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39myticklabels \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "layer_sizes = [size*size*3, 128, 64, len(classnames_array)]\n",
    "layer_array = (ctypes.c_int * len(layer_sizes))(*layer_sizes)\n",
    "model = mlp.create_mlp_model(layer_array, len(layer_sizes) - 1)\n",
    "mlp.set_logger(logger_callback)\n",
    "\n",
    "np.random.shuffle(data)\n",
    "split_index = int(len(data) * 0.8)\n",
    "data_train = data[:split_index]\n",
    "data_test = data[split_index:]\n",
    "X_train = np.array([item[1] for item in data_train], dtype=np.float32)\n",
    "Y_train = np.array([item[0] for item in data_train], dtype=np.float32)\n",
    "X_test = np.array([item[1] for item in data_test], dtype=np.float32)\n",
    "Y_test = np.array([item[0] for item in data_test], dtype=np.float32)\n",
    "\n",
    "X_train_reshaped = X_train.reshape((X_train.shape[0], -1))  # (N, 3072)\n",
    "X_train_c = X_train_reshaped.ctypes.data_as(ctypes.POINTER(ctypes.c_float))\n",
    "Y_train_c = Y_train.ctypes.data_as(ctypes.POINTER(ctypes.c_float))\n",
    "X_test_reshaped = X_test.reshape((X_test.shape[0], -1))  # (N, 3072)\n",
    "X_test_c = X_test_reshaped.ctypes.data_as(ctypes.POINTER(ctypes.c_float))\n",
    "Y_test_c = Y_test.ctypes.data_as(ctypes.POINTER(ctypes.c_float))\n",
    "\n",
    "epochs = 1000\n",
    "learning_rate = 0.01\n",
    "batch_size = 32\n",
    "\n",
    "with open(\"log.csv\", \"w\") as csvfile:\n",
    "        csvfile.truncate()\n",
    "        csvfile.write(\"epoch,accuracy,loss\\n\")\n",
    "time.sleep(0.2)\n",
    "\n",
    "mlp.train_mlp_model(model, X_train_c, Y_train_c, len(data_train), epochs, learning_rate, batch_size, True, b\"tanh\", X_test_c, Y_test_c, len(data_test))\n",
    "\n",
    "output_dim = len(classnames_array)\n",
    "matrix = (ctypes.c_int * (output_dim * output_dim))()\n",
    "mlp.evaluate_confusion_matrix(model, X_test_c, Y_test_c, len(data_test), True)\n",
    "mlp.get_confusion_matrix(model, matrix)\n",
    "\n",
    "mlp.release_mlp_model(model)\n",
    "\n",
    "# Conversion en numpy array\n",
    "confusion_np = np.ctypeslib.as_array(matrix).reshape((output_dim, output_dim))\n",
    "print(confusion_np)\n",
    "import seaborn as sns\n",
    "\n",
    "# Matrice de confusion fournie\n",
    "\n",
    "classnames_array = ['buffalo', 'elephant', 'zebre']\n",
    "\n",
    "# Affichage avec Seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.set(font_scale=1.2)\n",
    "ax = sns.heatmap(confusion_np, annot=True, fmt='d', cmap='Blues', \n",
    "                 xticklabels=classnames_array, yticklabels=classnames_array[::-1],\n",
    "                 linewidths=1, linecolor='gray', cbar=True)\n",
    "\n",
    "plt.title(\"Matrice de confusion\", fontsize=16)\n",
    "plt.xlabel(\"Classe prédite\", fontsize=14)\n",
    "plt.ylabel(\"Classe réelle\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd9f817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beac8d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "30/30 - 1s - 32ms/step - accuracy: 0.3294 - loss: 2.3289 - val_accuracy: 0.3207 - val_loss: 1.2150\n",
      "Epoch 2/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.4068 - loss: 1.1156 - val_accuracy: 0.5612 - val_loss: 0.9969\n",
      "Epoch 3/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.4449 - loss: 1.0289 - val_accuracy: 0.5105 - val_loss: 0.9973\n",
      "Epoch 4/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.4703 - loss: 1.0187 - val_accuracy: 0.5865 - val_loss: 0.9237\n",
      "Epoch 5/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.5148 - loss: 0.9672 - val_accuracy: 0.5612 - val_loss: 0.8951\n",
      "Epoch 6/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.5212 - loss: 0.9647 - val_accuracy: 0.5696 - val_loss: 0.9445\n",
      "Epoch 7/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.5572 - loss: 0.9203 - val_accuracy: 0.5401 - val_loss: 0.9073\n",
      "Epoch 8/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.5466 - loss: 0.9039 - val_accuracy: 0.6118 - val_loss: 0.8593\n",
      "Epoch 9/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.5847 - loss: 0.8632 - val_accuracy: 0.5781 - val_loss: 0.8501\n",
      "Epoch 10/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.5890 - loss: 0.8343 - val_accuracy: 0.5823 - val_loss: 0.8768\n",
      "Epoch 11/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.5932 - loss: 0.8287 - val_accuracy: 0.5949 - val_loss: 0.8570\n",
      "Epoch 12/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.6028 - loss: 0.8239 - val_accuracy: 0.6118 - val_loss: 0.8869\n",
      "Epoch 13/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.6144 - loss: 0.8347 - val_accuracy: 0.6118 - val_loss: 0.8439\n",
      "Epoch 14/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.6112 - loss: 0.8543 - val_accuracy: 0.6203 - val_loss: 0.8336\n",
      "Epoch 15/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.6367 - loss: 0.8090 - val_accuracy: 0.5865 - val_loss: 0.9208\n",
      "Epoch 16/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.6356 - loss: 0.8027 - val_accuracy: 0.5443 - val_loss: 0.9928\n",
      "Epoch 17/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.5943 - loss: 0.8489 - val_accuracy: 0.6329 - val_loss: 0.8678\n",
      "Epoch 18/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.6133 - loss: 0.8365 - val_accuracy: 0.6329 - val_loss: 0.8687\n",
      "Epoch 19/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.6303 - loss: 0.7921 - val_accuracy: 0.6203 - val_loss: 0.8055\n",
      "Epoch 20/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.6674 - loss: 0.7446 - val_accuracy: 0.5401 - val_loss: 0.9605\n",
      "Epoch 21/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.6568 - loss: 0.7749 - val_accuracy: 0.6203 - val_loss: 0.8438\n",
      "Epoch 22/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.6769 - loss: 0.7389 - val_accuracy: 0.5021 - val_loss: 1.0156\n",
      "Epoch 23/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.6462 - loss: 0.7752 - val_accuracy: 0.5738 - val_loss: 0.9178\n",
      "Epoch 24/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.6208 - loss: 0.8101 - val_accuracy: 0.6034 - val_loss: 0.8411\n",
      "Epoch 25/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.6578 - loss: 0.7299 - val_accuracy: 0.6076 - val_loss: 0.8600\n",
      "Epoch 26/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.6864 - loss: 0.7061 - val_accuracy: 0.6076 - val_loss: 0.9039\n",
      "Epoch 27/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.6515 - loss: 0.7422 - val_accuracy: 0.6160 - val_loss: 0.8769\n",
      "Epoch 28/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.6653 - loss: 0.7465 - val_accuracy: 0.4937 - val_loss: 1.1408\n",
      "Epoch 29/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.6515 - loss: 0.7458 - val_accuracy: 0.6414 - val_loss: 0.8531\n",
      "Epoch 30/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.6843 - loss: 0.7257 - val_accuracy: 0.6160 - val_loss: 0.8985\n",
      "Epoch 31/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.6282 - loss: 0.8079 - val_accuracy: 0.6245 - val_loss: 0.8801\n",
      "Epoch 32/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.6790 - loss: 0.7378 - val_accuracy: 0.5992 - val_loss: 0.9251\n",
      "Epoch 33/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.6430 - loss: 0.7795 - val_accuracy: 0.5992 - val_loss: 0.9433\n",
      "Epoch 34/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.6780 - loss: 0.7247 - val_accuracy: 0.6076 - val_loss: 0.8336\n",
      "Epoch 35/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.6875 - loss: 0.7259 - val_accuracy: 0.6076 - val_loss: 0.9435\n",
      "Epoch 36/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.6907 - loss: 0.7173 - val_accuracy: 0.5738 - val_loss: 0.9140\n",
      "Epoch 37/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.6557 - loss: 0.7433 - val_accuracy: 0.5527 - val_loss: 1.1522\n",
      "Epoch 38/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.6737 - loss: 0.7481 - val_accuracy: 0.5907 - val_loss: 0.8611\n",
      "Epoch 39/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7225 - loss: 0.6567 - val_accuracy: 0.5865 - val_loss: 0.9136\n",
      "Epoch 40/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.6483 - loss: 0.7730 - val_accuracy: 0.6076 - val_loss: 0.8633\n",
      "Epoch 41/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.6992 - loss: 0.6751 - val_accuracy: 0.6034 - val_loss: 1.0155\n",
      "Epoch 42/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.6727 - loss: 0.7405 - val_accuracy: 0.5992 - val_loss: 0.8416\n",
      "Epoch 43/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7320 - loss: 0.6387 - val_accuracy: 0.5865 - val_loss: 0.9031\n",
      "Epoch 44/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7161 - loss: 0.6399 - val_accuracy: 0.5823 - val_loss: 0.9878\n",
      "Epoch 45/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.6875 - loss: 0.7187 - val_accuracy: 0.5992 - val_loss: 1.0423\n",
      "Epoch 46/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7373 - loss: 0.6488 - val_accuracy: 0.5992 - val_loss: 0.8740\n",
      "Epoch 47/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7161 - loss: 0.6608 - val_accuracy: 0.5781 - val_loss: 0.9289\n",
      "Epoch 48/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7013 - loss: 0.6730 - val_accuracy: 0.6203 - val_loss: 0.9457\n",
      "Epoch 49/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7055 - loss: 0.6646 - val_accuracy: 0.5949 - val_loss: 0.9240\n",
      "Epoch 50/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7595 - loss: 0.5857 - val_accuracy: 0.5992 - val_loss: 0.9266\n",
      "Epoch 51/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7246 - loss: 0.6473 - val_accuracy: 0.5949 - val_loss: 0.9570\n",
      "Epoch 52/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7574 - loss: 0.5779 - val_accuracy: 0.6203 - val_loss: 1.0137\n",
      "Epoch 53/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7669 - loss: 0.6011 - val_accuracy: 0.5907 - val_loss: 1.1282\n",
      "Epoch 54/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7617 - loss: 0.5721 - val_accuracy: 0.5907 - val_loss: 1.0465\n",
      "Epoch 55/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7701 - loss: 0.5851 - val_accuracy: 0.6076 - val_loss: 0.9386\n",
      "Epoch 56/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7775 - loss: 0.5628 - val_accuracy: 0.4726 - val_loss: 1.7007\n",
      "Epoch 57/200\n",
      "30/30 - 0s - 6ms/step - accuracy: 0.7023 - loss: 0.7320 - val_accuracy: 0.6034 - val_loss: 0.9527\n",
      "Epoch 58/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7341 - loss: 0.6462 - val_accuracy: 0.6371 - val_loss: 0.8431\n",
      "Epoch 59/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7055 - loss: 0.6778 - val_accuracy: 0.5781 - val_loss: 0.9933\n",
      "Epoch 60/200\n",
      "30/30 - 0s - 6ms/step - accuracy: 0.7680 - loss: 0.5749 - val_accuracy: 0.5949 - val_loss: 0.9026\n",
      "Epoch 61/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7828 - loss: 0.5379 - val_accuracy: 0.6245 - val_loss: 0.8675\n",
      "Epoch 62/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7744 - loss: 0.5362 - val_accuracy: 0.5907 - val_loss: 0.9563\n",
      "Epoch 63/200\n",
      "30/30 - 0s - 6ms/step - accuracy: 0.7542 - loss: 0.6024 - val_accuracy: 0.6203 - val_loss: 0.8706\n",
      "Epoch 64/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7797 - loss: 0.5428 - val_accuracy: 0.6203 - val_loss: 0.9379\n",
      "Epoch 65/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7998 - loss: 0.4981 - val_accuracy: 0.6203 - val_loss: 0.9658\n",
      "Epoch 66/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7669 - loss: 0.5706 - val_accuracy: 0.6160 - val_loss: 0.9348\n",
      "Epoch 67/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7606 - loss: 0.6057 - val_accuracy: 0.5907 - val_loss: 0.9267\n",
      "Epoch 68/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7521 - loss: 0.5834 - val_accuracy: 0.5063 - val_loss: 1.3212\n",
      "Epoch 69/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7669 - loss: 0.5666 - val_accuracy: 0.5992 - val_loss: 1.0638\n",
      "Epoch 70/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.6992 - loss: 0.7298 - val_accuracy: 0.6371 - val_loss: 0.9305\n",
      "Epoch 71/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7627 - loss: 0.5949 - val_accuracy: 0.4810 - val_loss: 1.6867\n",
      "Epoch 72/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.6886 - loss: 0.7487 - val_accuracy: 0.6540 - val_loss: 0.8242\n",
      "Epoch 73/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7585 - loss: 0.6046 - val_accuracy: 0.6034 - val_loss: 0.8501\n",
      "Epoch 74/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7373 - loss: 0.6347 - val_accuracy: 0.6118 - val_loss: 0.8265\n",
      "Epoch 75/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7500 - loss: 0.5926 - val_accuracy: 0.6118 - val_loss: 0.9409\n",
      "Epoch 76/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7521 - loss: 0.5844 - val_accuracy: 0.6414 - val_loss: 0.8144\n",
      "Epoch 77/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7638 - loss: 0.5834 - val_accuracy: 0.6160 - val_loss: 0.9024\n",
      "Epoch 78/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7341 - loss: 0.6158 - val_accuracy: 0.5612 - val_loss: 0.9554\n",
      "Epoch 79/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7744 - loss: 0.5538 - val_accuracy: 0.6076 - val_loss: 0.9453\n",
      "Epoch 80/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8019 - loss: 0.4993 - val_accuracy: 0.5316 - val_loss: 1.2361\n",
      "Epoch 81/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7913 - loss: 0.5137 - val_accuracy: 0.6076 - val_loss: 1.0039\n",
      "Epoch 82/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7797 - loss: 0.5579 - val_accuracy: 0.5949 - val_loss: 1.0390\n",
      "Epoch 83/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7765 - loss: 0.5307 - val_accuracy: 0.5949 - val_loss: 0.9348\n",
      "Epoch 84/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7839 - loss: 0.5522 - val_accuracy: 0.6034 - val_loss: 0.9098\n",
      "Epoch 85/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7680 - loss: 0.5879 - val_accuracy: 0.6118 - val_loss: 0.8787\n",
      "Epoch 86/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7903 - loss: 0.5476 - val_accuracy: 0.5907 - val_loss: 0.9627\n",
      "Epoch 87/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8284 - loss: 0.4456 - val_accuracy: 0.5949 - val_loss: 1.0571\n",
      "Epoch 88/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8347 - loss: 0.4270 - val_accuracy: 0.6076 - val_loss: 0.9830\n",
      "Epoch 89/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8199 - loss: 0.4780 - val_accuracy: 0.5612 - val_loss: 1.1781\n",
      "Epoch 90/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8347 - loss: 0.4331 - val_accuracy: 0.6287 - val_loss: 0.9791\n",
      "Epoch 91/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8400 - loss: 0.4249 - val_accuracy: 0.6160 - val_loss: 1.0375\n",
      "Epoch 92/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7903 - loss: 0.5435 - val_accuracy: 0.4810 - val_loss: 1.2957\n",
      "Epoch 93/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7903 - loss: 0.5368 - val_accuracy: 0.5781 - val_loss: 1.0158\n",
      "Epoch 94/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8305 - loss: 0.4581 - val_accuracy: 0.5949 - val_loss: 1.0036\n",
      "Epoch 95/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8369 - loss: 0.4173 - val_accuracy: 0.6160 - val_loss: 1.0749\n",
      "Epoch 96/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8061 - loss: 0.4718 - val_accuracy: 0.5401 - val_loss: 1.1346\n",
      "Epoch 97/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8294 - loss: 0.4529 - val_accuracy: 0.5696 - val_loss: 1.0849\n",
      "Epoch 98/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8305 - loss: 0.4448 - val_accuracy: 0.5612 - val_loss: 1.2102\n",
      "Epoch 99/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8475 - loss: 0.4131 - val_accuracy: 0.6456 - val_loss: 0.9497\n",
      "Epoch 100/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8337 - loss: 0.4294 - val_accuracy: 0.5907 - val_loss: 1.0680\n",
      "Epoch 101/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8199 - loss: 0.4628 - val_accuracy: 0.5696 - val_loss: 1.1802\n",
      "Epoch 102/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7871 - loss: 0.5895 - val_accuracy: 0.5232 - val_loss: 1.2472\n",
      "Epoch 103/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7913 - loss: 0.5221 - val_accuracy: 0.5949 - val_loss: 1.0392\n",
      "Epoch 104/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8178 - loss: 0.4617 - val_accuracy: 0.6076 - val_loss: 1.1045\n",
      "Epoch 105/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8549 - loss: 0.3870 - val_accuracy: 0.5738 - val_loss: 1.1438\n",
      "Epoch 106/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8379 - loss: 0.4014 - val_accuracy: 0.5865 - val_loss: 1.0687\n",
      "Epoch 107/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8072 - loss: 0.5072 - val_accuracy: 0.5738 - val_loss: 1.0322\n",
      "Epoch 108/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8210 - loss: 0.4506 - val_accuracy: 0.5401 - val_loss: 1.5822\n",
      "Epoch 109/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8231 - loss: 0.4553 - val_accuracy: 0.5781 - val_loss: 1.0813\n",
      "Epoch 110/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8443 - loss: 0.4273 - val_accuracy: 0.6287 - val_loss: 0.9513\n",
      "Epoch 111/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8623 - loss: 0.3675 - val_accuracy: 0.5696 - val_loss: 1.3593\n",
      "Epoch 112/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8008 - loss: 0.5178 - val_accuracy: 0.5359 - val_loss: 1.2739\n",
      "Epoch 113/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7797 - loss: 0.5610 - val_accuracy: 0.5907 - val_loss: 0.9230\n",
      "Epoch 114/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8347 - loss: 0.4373 - val_accuracy: 0.5781 - val_loss: 1.1517\n",
      "Epoch 115/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8602 - loss: 0.3512 - val_accuracy: 0.5992 - val_loss: 1.4306\n",
      "Epoch 116/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8729 - loss: 0.3552 - val_accuracy: 0.5696 - val_loss: 1.2314\n",
      "Epoch 117/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8602 - loss: 0.3638 - val_accuracy: 0.5781 - val_loss: 1.3025\n",
      "Epoch 118/200\n",
      "30/30 - 0s - 6ms/step - accuracy: 0.8761 - loss: 0.3542 - val_accuracy: 0.6203 - val_loss: 1.1897\n",
      "Epoch 119/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8517 - loss: 0.3768 - val_accuracy: 0.6034 - val_loss: 1.1002\n",
      "Epoch 120/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8623 - loss: 0.3487 - val_accuracy: 0.5781 - val_loss: 1.1576\n",
      "Epoch 121/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8697 - loss: 0.3492 - val_accuracy: 0.5781 - val_loss: 1.4674\n",
      "Epoch 122/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8856 - loss: 0.3126 - val_accuracy: 0.5823 - val_loss: 1.6364\n",
      "Epoch 123/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8125 - loss: 0.4908 - val_accuracy: 0.5738 - val_loss: 1.1168\n",
      "Epoch 124/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7881 - loss: 0.5310 - val_accuracy: 0.6245 - val_loss: 0.9572\n",
      "Epoch 125/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8782 - loss: 0.3674 - val_accuracy: 0.5781 - val_loss: 1.4569\n",
      "Epoch 126/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8390 - loss: 0.4095 - val_accuracy: 0.6287 - val_loss: 1.0465\n",
      "Epoch 127/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8528 - loss: 0.4032 - val_accuracy: 0.5907 - val_loss: 1.4086\n",
      "Epoch 128/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8464 - loss: 0.4145 - val_accuracy: 0.5992 - val_loss: 1.1668\n",
      "Epoch 129/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8909 - loss: 0.3039 - val_accuracy: 0.5654 - val_loss: 1.5298\n",
      "Epoch 130/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8570 - loss: 0.3708 - val_accuracy: 0.5781 - val_loss: 1.2076\n",
      "Epoch 131/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8475 - loss: 0.4070 - val_accuracy: 0.5823 - val_loss: 1.4493\n",
      "Epoch 132/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.9004 - loss: 0.2855 - val_accuracy: 0.5527 - val_loss: 1.5728\n",
      "Epoch 133/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8464 - loss: 0.3790 - val_accuracy: 0.5696 - val_loss: 1.4213\n",
      "Epoch 134/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8633 - loss: 0.3611 - val_accuracy: 0.6118 - val_loss: 1.1732\n",
      "Epoch 135/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8379 - loss: 0.4180 - val_accuracy: 0.5992 - val_loss: 1.1860\n",
      "Epoch 136/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8761 - loss: 0.3342 - val_accuracy: 0.5527 - val_loss: 1.8219\n",
      "Epoch 137/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8633 - loss: 0.3443 - val_accuracy: 0.5359 - val_loss: 1.7315\n",
      "Epoch 138/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.5593 - loss: 0.9533 - val_accuracy: 0.5443 - val_loss: 1.0732\n",
      "Epoch 139/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7924 - loss: 0.5362 - val_accuracy: 0.6076 - val_loss: 1.1477\n",
      "Epoch 140/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8919 - loss: 0.3436 - val_accuracy: 0.6118 - val_loss: 1.5208\n",
      "Epoch 141/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8750 - loss: 0.3663 - val_accuracy: 0.6118 - val_loss: 1.4614\n",
      "Epoch 142/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8909 - loss: 0.3304 - val_accuracy: 0.5865 - val_loss: 1.5903\n",
      "Epoch 143/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8761 - loss: 0.3632 - val_accuracy: 0.5612 - val_loss: 1.9996\n",
      "Epoch 144/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8983 - loss: 0.3113 - val_accuracy: 0.5570 - val_loss: 1.8795\n",
      "Epoch 145/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8962 - loss: 0.3042 - val_accuracy: 0.5865 - val_loss: 1.5184\n",
      "Epoch 146/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8845 - loss: 0.3031 - val_accuracy: 0.5443 - val_loss: 1.7936\n",
      "Epoch 147/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8930 - loss: 0.2976 - val_accuracy: 0.5865 - val_loss: 1.7879\n",
      "Epoch 148/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8792 - loss: 0.3238 - val_accuracy: 0.6034 - val_loss: 1.5680\n",
      "Epoch 149/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8877 - loss: 0.3079 - val_accuracy: 0.5865 - val_loss: 1.5842\n",
      "Epoch 150/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.9036 - loss: 0.2662 - val_accuracy: 0.5907 - val_loss: 1.4450\n",
      "Epoch 151/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7966 - loss: 0.5197 - val_accuracy: 0.5654 - val_loss: 1.3521\n",
      "Epoch 152/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8083 - loss: 0.4953 - val_accuracy: 0.6034 - val_loss: 1.0780\n",
      "Epoch 153/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8686 - loss: 0.3453 - val_accuracy: 0.5907 - val_loss: 1.1277\n",
      "Epoch 154/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8591 - loss: 0.3770 - val_accuracy: 0.5907 - val_loss: 1.3973\n",
      "Epoch 155/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8665 - loss: 0.3692 - val_accuracy: 0.5781 - val_loss: 1.6194\n",
      "Epoch 156/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8506 - loss: 0.3844 - val_accuracy: 0.5865 - val_loss: 1.1912\n",
      "Epoch 157/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8856 - loss: 0.3050 - val_accuracy: 0.5527 - val_loss: 1.6175\n",
      "Epoch 158/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8856 - loss: 0.3018 - val_accuracy: 0.5865 - val_loss: 1.5481\n",
      "Epoch 159/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.9153 - loss: 0.2459 - val_accuracy: 0.5823 - val_loss: 1.5143\n",
      "Epoch 160/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.9174 - loss: 0.2420 - val_accuracy: 0.6076 - val_loss: 1.6610\n",
      "Epoch 161/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8761 - loss: 0.3359 - val_accuracy: 0.5907 - val_loss: 1.5065\n",
      "Epoch 162/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.9089 - loss: 0.2703 - val_accuracy: 0.5443 - val_loss: 2.0127\n",
      "Epoch 163/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8729 - loss: 0.3351 - val_accuracy: 0.5738 - val_loss: 1.8293\n",
      "Epoch 164/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.9248 - loss: 0.2189 - val_accuracy: 0.5823 - val_loss: 1.7090\n",
      "Epoch 165/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.9078 - loss: 0.2620 - val_accuracy: 0.5949 - val_loss: 1.6404\n",
      "Epoch 166/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8358 - loss: 0.5595 - val_accuracy: 0.4051 - val_loss: 1.2926\n",
      "Epoch 167/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.7278 - loss: 0.6661 - val_accuracy: 0.5823 - val_loss: 1.2081\n",
      "Epoch 168/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8994 - loss: 0.3215 - val_accuracy: 0.5992 - val_loss: 1.3325\n",
      "Epoch 169/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.9068 - loss: 0.2840 - val_accuracy: 0.5654 - val_loss: 1.8314\n",
      "Epoch 170/200\n",
      "30/30 - 0s - 6ms/step - accuracy: 0.7193 - loss: 0.6617 - val_accuracy: 0.6076 - val_loss: 1.3448\n",
      "Epoch 171/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8178 - loss: 0.4730 - val_accuracy: 0.5823 - val_loss: 1.5353\n",
      "Epoch 172/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.9036 - loss: 0.2991 - val_accuracy: 0.5612 - val_loss: 2.0774\n",
      "Epoch 173/200\n",
      "30/30 - 0s - 6ms/step - accuracy: 0.8570 - loss: 0.4109 - val_accuracy: 0.5570 - val_loss: 1.6856\n",
      "Epoch 174/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8475 - loss: 0.4346 - val_accuracy: 0.5738 - val_loss: 1.3213\n",
      "Epoch 175/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8941 - loss: 0.3008 - val_accuracy: 0.5949 - val_loss: 1.3465\n",
      "Epoch 176/200\n",
      "30/30 - 0s - 6ms/step - accuracy: 0.8782 - loss: 0.3459 - val_accuracy: 0.5781 - val_loss: 1.5330\n",
      "Epoch 177/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.9206 - loss: 0.2525 - val_accuracy: 0.5992 - val_loss: 1.5400\n",
      "Epoch 178/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.9333 - loss: 0.2304 - val_accuracy: 0.5570 - val_loss: 1.9417\n",
      "Epoch 179/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.9163 - loss: 0.2589 - val_accuracy: 0.5738 - val_loss: 1.9258\n",
      "Epoch 180/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8867 - loss: 0.3285 - val_accuracy: 0.6203 - val_loss: 1.3996\n",
      "Epoch 181/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8570 - loss: 0.3959 - val_accuracy: 0.5696 - val_loss: 1.9153\n",
      "Epoch 182/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8400 - loss: 0.4215 - val_accuracy: 0.5527 - val_loss: 1.3704\n",
      "Epoch 183/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8358 - loss: 0.4159 - val_accuracy: 0.5527 - val_loss: 1.2390\n",
      "Epoch 184/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8951 - loss: 0.2871 - val_accuracy: 0.5654 - val_loss: 1.4963\n",
      "Epoch 185/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.9195 - loss: 0.2346 - val_accuracy: 0.5612 - val_loss: 1.8430\n",
      "Epoch 186/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.9184 - loss: 0.2364 - val_accuracy: 0.5823 - val_loss: 1.5535\n",
      "Epoch 187/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8104 - loss: 0.5235 - val_accuracy: 0.6329 - val_loss: 1.2858\n",
      "Epoch 188/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8803 - loss: 0.3208 - val_accuracy: 0.5612 - val_loss: 1.6046\n",
      "Epoch 189/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.9375 - loss: 0.2176 - val_accuracy: 0.5612 - val_loss: 2.0377\n",
      "Epoch 190/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8941 - loss: 0.2771 - val_accuracy: 0.5527 - val_loss: 1.8508\n",
      "Epoch 191/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.9142 - loss: 0.2357 - val_accuracy: 0.5612 - val_loss: 2.0748\n",
      "Epoch 192/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.9269 - loss: 0.2036 - val_accuracy: 0.5738 - val_loss: 2.1069\n",
      "Epoch 193/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.9131 - loss: 0.2498 - val_accuracy: 0.5443 - val_loss: 2.4873\n",
      "Epoch 194/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.9078 - loss: 0.2529 - val_accuracy: 0.5612 - val_loss: 2.1445\n",
      "Epoch 195/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.9227 - loss: 0.2248 - val_accuracy: 0.5696 - val_loss: 1.9172\n",
      "Epoch 196/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8867 - loss: 0.3068 - val_accuracy: 0.5907 - val_loss: 1.5067\n",
      "Epoch 197/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.9184 - loss: 0.2265 - val_accuracy: 0.5612 - val_loss: 1.9914\n",
      "Epoch 198/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.9375 - loss: 0.1860 - val_accuracy: 0.5654 - val_loss: 1.9410\n",
      "Epoch 199/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.9237 - loss: 0.2107 - val_accuracy: 0.5907 - val_loss: 2.1307\n",
      "Epoch 200/200\n",
      "30/30 - 0s - 5ms/step - accuracy: 0.8930 - loss: 0.3265 - val_accuracy: 0.5105 - val_loss: 2.1431\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and multiclass targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test_reshaped)\n\u001b[0;32m     45\u001b[0m pred_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 46\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lgrdp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\lgrdp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:220\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \n\u001b[0;32m    156\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 220\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\lgrdp\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m     95\u001b[0m             type_true, type_pred\n\u001b[0;32m     96\u001b[0m         )\n\u001b[0;32m     97\u001b[0m     )\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[0;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and multiclass targets"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train_reshaped = X_train.reshape((X_train.shape[0], -1))\n",
    "X_test_reshaped = X_test.reshape((X_test.shape[0], -1))\n",
    "Y_train_cat = to_categorical(Y_train, num_classes=len(classnames_array))\n",
    "Y_test_cat = to_categorical(Y_test, num_classes=len(classnames_array))\n",
    "\n",
    "def ensure_categorical(Y, num_classes):\n",
    "    Y = np.array(Y)\n",
    "    if len(Y.shape) == 1:\n",
    "        return to_categorical(Y, num_classes)\n",
    "    elif Y.shape[1] == num_classes:\n",
    "        return Y \n",
    "    else:\n",
    "        raise ValueError(f\"Format inattendu pour Y (shape: {Y.shape})\")\n",
    "\n",
    "Y_train_cat = ensure_categorical(Y_train, len(classnames_array))\n",
    "Y_test_cat = ensure_categorical(Y_test, len(classnames_array))\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train_reshaped.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(len(classnames_array), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.01),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_reshaped, Y_train_cat,\n",
    "          epochs=200,\n",
    "          batch_size=32,\n",
    "          validation_data=(X_test_reshaped, Y_test_cat),\n",
    "          verbose=2)\n",
    "\n",
    "predictions = model.predict(X_test_reshaped)\n",
    "pred_labels = np.argmax(predictions, axis=1)\n",
    "acc = accuracy_score(Y_test, pred_labels)\n",
    "print(f\"\\nTest Accuracy: {acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdee9f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f6c8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted class : buffalo\n",
      "[0.6341931223869324, 0.0993126854300499, 0.2664942145347595]\n"
     ]
    }
   ],
   "source": [
    "img = Image.open('C:/Users/lgrdp/Downloads/images (10).jpeg').convert(\"RGB\")\n",
    "img = img.resize(size=(32,32))\n",
    "img_data = np.array(img) / 255.0\n",
    "\n",
    "output_array = mlp.predict_mlp_model(model, img_data.ctypes.data_as(ctypes.POINTER(ctypes.c_float)), True)\n",
    "output_array = ctypes.cast(output_array, ctypes.POINTER(ctypes.c_float * layer_sizes[-1])).contents\n",
    "output = list(output_array)\n",
    "class_index = 0\n",
    "for i in range(len(output)):\n",
    "    if output[i] == max(output):\n",
    "        class_index = i\n",
    "print('predicted class : ' + classnames_array[class_index])\n",
    "print(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
